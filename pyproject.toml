[project]
name = "project-1"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "aiofiles>=24.1.0",
    "fastapi[standard]>=0.115.8",
    "httpx>=0.28.1",
    "just>=0.8.162",
    "langchain>=0.3.22",
    "langchain-community>=0.3.20",
    "loguru>=0.7.3",
    "mkdocs-material>=9.6.5",
    "ollama>=0.4.7",
    "openai-whisper>=20240930",
    "pandas>=2.2.3",
    "plotly>=6.0.0",
    "pyannote-audio>=3.3.2",
    "rapidfuzz>=3.12.1",
    "ray[serve]>=2.46.0",
    "rich>=13.9.4",
    "ruff>=0.11.2",
    "streamlit>=1.42.0",
    "textblob>=0.19.0",
    "tomli>=2.2.1",
    "zmq>=0.0.0",
]


[tool.ruff]
select = ["ALL"]
ignore = ["N999"]
line-length = 190


[tool.ruff.lint]
select = ["ALL"]
ignore = ["S307","N999"]  # ignore use of eval() ...alternative suggested was causing code to crash when invoking functions directly based on llm output.

[tool.ruff.lint.pylint]
# This was required as some frontend functions need to be over the threshold statements length. Splitting them causes UI to fail
max-statements = 50
